{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d083f1",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Data-Preprocessing-(Data-Transformations)\" data-toc-modified-id=\"Data-Preprocessing-(Data-Transformations)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing (Data Transformations)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Drug-Outcome-variable-transformations\" data-toc-modified-id=\"Drug-Outcome-variable-transformations-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Drug Outcome variable transformations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Remove-string-and-change-to-integer\" data-toc-modified-id=\"Remove-string-and-change-to-integer-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Remove string and change to integer</a></span></li><li><span><a href=\"#Create-3-broader-outcome-variables-(Stimulants,-Depressants-and-Hallucinogens)\" data-toc-modified-id=\"Create-3-broader-outcome-variables-(Stimulants,-Depressants-and-Hallucinogens)-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Create 3 broader outcome variables (<em>Stimulants, Depressants and Hallucinogens</em>)</a></span></li><li><span><a href=\"#Recode-from-6-levels-to-3-levels\" data-toc-modified-id=\"Recode-from-6-levels-to-3-levels-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Recode from 6 levels to 3 levels</a></span></li></ul></li></ul></li><li><span><a href=\"#Initial-Models\" data-toc-modified-id=\"Initial-Models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Initial Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Support Vector Machine</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#k-NN-classifier\" data-toc-modified-id=\"k-NN-classifier-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>k-NN classifier</a></span></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Gradient-Boosted-Trees\" data-toc-modified-id=\"Gradient-Boosted-Trees-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Gradient Boosted Trees</a></span></li><li><span><a href=\"#Linear-Discriminant-Analysis-(LDA)\" data-toc-modified-id=\"Linear-Discriminant-Analysis-(LDA)-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Linear Discriminant Analysis (LDA)</a></span></li><li><span><a href=\"#Neural-Network\" data-toc-modified-id=\"Neural-Network-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Neural Network</a></span></li></ul></li><li><span><a href=\"#Rebalance\" data-toc-modified-id=\"Rebalance-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Rebalance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Rebalanced---Linear-Classifier\" data-toc-modified-id=\"Rebalanced---Linear-Classifier-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Rebalanced - Linear Classifier</a></span></li><li><span><a href=\"#Rebalanced---Logistic-Regression\" data-toc-modified-id=\"Rebalanced---Logistic-Regression-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Rebalanced - Logistic Regression</a></span></li><li><span><a href=\"#Rebalanced----K-nn-classifier\" data-toc-modified-id=\"Rebalanced----K-nn-classifier-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Rebalanced  - K-nn classifier</a></span></li><li><span><a href=\"#Rebalanced---Decision-Tree\" data-toc-modified-id=\"Rebalanced---Decision-Tree-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Rebalanced - Decision Tree</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-pruning-to-prevent-over-fitting---Determining-the-correct-ccp_alpha\" data-toc-modified-id=\"Using-pruning-to-prevent-over-fitting---Determining-the-correct-ccp_alpha-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Using pruning to prevent over fitting - Determining the correct ccp_alpha</a></span></li><li><span><a href=\"#Fit-Using-the-alpha-determined-above-(0.05)---most-stable-accuracy-across-increasing-alphas\" data-toc-modified-id=\"Fit-Using-the-alpha-determined-above-(0.05)---most-stable-accuracy-across-increasing-alphas-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Fit Using the alpha determined above (0.05) - most stable accuracy across increasing alphas</a></span></li></ul></li><li><span><a href=\"#Rebalanced---Boosted-Tree\" data-toc-modified-id=\"Rebalanced---Boosted-Tree-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Rebalanced - Boosted Tree</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fit-Using-the-alpha-determined-above-(0.05)---most-stable-accuracy-across-increasing-alphas\" data-toc-modified-id=\"Fit-Using-the-alpha-determined-above-(0.05)---most-stable-accuracy-across-increasing-alphas-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Fit Using the alpha determined above (0.05) - most stable accuracy across increasing alphas</a></span></li></ul></li><li><span><a href=\"#Rebalanced---Linear-Discriminant-Analysis-(LDA)\" data-toc-modified-id=\"Rebalanced---Linear-Discriminant-Analysis-(LDA)-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Rebalanced - Linear Discriminant Analysis (LDA)</a></span></li><li><span><a href=\"#Rebalanced---Neural-Network\" data-toc-modified-id=\"Rebalanced---Neural-Network-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Rebalanced - Neural Network</a></span></li></ul></li><li><span><a href=\"#Evaluation-Metrics---AUC-calculations-and-plots\" data-toc-modified-id=\"Evaluation-Metrics---AUC-calculations-and-plots-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluation Metrics - AUC calculations and plots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-Classifier---AUC\" data-toc-modified-id=\"Linear-Classifier---AUC-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Linear Classifier - AUC</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33bc222",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The first two sections of this module are indentical to 02b, however this module then builds on that work by adding two new sections:\n",
    "\n",
    "1. Re-balancing Data using SMOTE to Oversample - Followed by a Re-calibrating of the Models\n",
    "2. Developing an implementation of the calculation of the AUC score which allow plots to be generated for the final models\n",
    "3. The beginning development of the parameter grid for GridSearchCV function is also in this last section.\n",
    "\n",
    "Once completed, this module's scripts provide the basis for carrying out the entire modelling process from data cleaning, to re-balancing to creating the final models and retrieving the final metric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d60a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82dbb5",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Data Transformations)\n",
    "\n",
    "In this first section, the dataset is prepared for modelling in a series of data transformations.\n",
    "\n",
    "For the outcome variable, the eighteen outcome variables are collapsed into three new outcome variables, representing broader classes of drugs. They are _**Stimulants, Depressants, and Hallucinogens**_.\n",
    "\n",
    "Additionally, the 7 levels of drug use are also collapsed to three new levels of drug use: _**1 - unlike to use, 2 - medium use, 3 - high usage**_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3e179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>NEO_N</th>\n",
       "      <th>NEO_E</th>\n",
       "      <th>NEO_O</th>\n",
       "      <th>NEO_A</th>\n",
       "      <th>...</th>\n",
       "      <th>ECST</th>\n",
       "      <th>HEROIN</th>\n",
       "      <th>KETA</th>\n",
       "      <th>LEGALH</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METH</th>\n",
       "      <th>MUSHRM</th>\n",
       "      <th>NICO</th>\n",
       "      <th>SEMER</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      Age   Gender  Education  Country  Ethnicity    NEO_N    NEO_E  \\\n",
       "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
       "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "        NEO_O    NEO_A  ...  ECST  HEROIN  KETA LEGALH  LSD METH MUSHRM NICO  \\\n",
       "0    -0.58331 -0.91699  ...   CL0     CL0   CL0    CL0  CL0  CL0    CL0  CL2   \n",
       "1     1.43533  0.76096  ...   CL4     CL0   CL2    CL0  CL2  CL3    CL0  CL4   \n",
       "2    -0.84732 -1.62090  ...   CL0     CL0   CL0    CL0  CL0  CL0    CL1  CL0   \n",
       "3    -0.01928  0.59042  ...   CL0     CL0   CL2    CL0  CL0  CL0    CL0  CL2   \n",
       "4    -0.45174 -0.30172  ...   CL1     CL0   CL0    CL1  CL0  CL0    CL2  CL2   \n",
       "...       ...      ...  ...   ...     ...   ...    ...  ...  ...    ...  ...   \n",
       "1880  1.88511  0.76096  ...   CL0     CL0   CL0    CL3  CL3  CL0    CL0  CL0   \n",
       "1881  0.58331  0.76096  ...   CL2     CL0   CL0    CL3  CL5  CL4    CL4  CL5   \n",
       "1882 -1.27553 -1.77200  ...   CL4     CL0   CL2    CL0  CL2  CL0    CL2  CL6   \n",
       "1883  0.29338 -1.62090  ...   CL3     CL0   CL0    CL3  CL3  CL0    CL3  CL4   \n",
       "1884  1.65653  1.11406  ...   CL3     CL0   CL0    CL3  CL3  CL0    CL3  CL6   \n",
       "\n",
       "     SEMER  VSA  \n",
       "0      CL0  CL0  \n",
       "1      CL0  CL0  \n",
       "2      CL0  CL0  \n",
       "3      CL0  CL0  \n",
       "4      CL0  CL0  \n",
       "...    ...  ...  \n",
       "1880   CL0  CL5  \n",
       "1881   CL0  CL0  \n",
       "1882   CL0  CL0  \n",
       "1883   CL0  CL0  \n",
       "1884   CL0  CL2  \n",
       "\n",
       "[1885 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in dataset\n",
    "df = pd.read_csv(\"../drug_consumption_cap_20230505.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70946d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6bd6006",
   "metadata": {},
   "source": [
    "## Drug Outcome variable transformations\n",
    "\n",
    "### Remove string and change to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a75440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALC</th>\n",
       "      <th>AMPHET</th>\n",
       "      <th>AMYL</th>\n",
       "      <th>BENZOS</th>\n",
       "      <th>CAFF</th>\n",
       "      <th>CANNABIS</th>\n",
       "      <th>CHOC</th>\n",
       "      <th>COCAINE</th>\n",
       "      <th>CRACK</th>\n",
       "      <th>ECST</th>\n",
       "      <th>HEROIN</th>\n",
       "      <th>KETA</th>\n",
       "      <th>LEGALH</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METH</th>\n",
       "      <th>MUSHRM</th>\n",
       "      <th>NICO</th>\n",
       "      <th>SEMER</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ALC AMPHET AMYL BENZOS CAFF CANNABIS CHOC COCAINE CRACK ECST HEROIN  \\\n",
       "0     CL5    CL2  CL0    CL2  CL6      CL0  CL5     CL0   CL0  CL0    CL0   \n",
       "1     CL5    CL2  CL2    CL0  CL6      CL4  CL6     CL3   CL0  CL4    CL0   \n",
       "2     CL6    CL0  CL0    CL0  CL6      CL3  CL4     CL0   CL0  CL0    CL0   \n",
       "3     CL4    CL0  CL0    CL3  CL5      CL2  CL4     CL2   CL0  CL0    CL0   \n",
       "4     CL4    CL1  CL1    CL0  CL6      CL3  CL6     CL0   CL0  CL1    CL0   \n",
       "...   ...    ...  ...    ...  ...      ...  ...     ...   ...  ...    ...   \n",
       "1880  CL5    CL0  CL0    CL0  CL4      CL5  CL4     CL0   CL0  CL0    CL0   \n",
       "1881  CL5    CL0  CL0    CL0  CL5      CL3  CL4     CL0   CL0  CL2    CL0   \n",
       "1882  CL4    CL6  CL5    CL5  CL6      CL6  CL6     CL4   CL0  CL4    CL0   \n",
       "1883  CL5    CL0  CL0    CL0  CL6      CL6  CL5     CL0   CL0  CL3    CL0   \n",
       "1884  CL4    CL3  CL0    CL3  CL6      CL3  CL6     CL3   CL0  CL3    CL0   \n",
       "\n",
       "     KETA LEGALH  LSD METH MUSHRM NICO SEMER  VSA  \n",
       "0     CL0    CL0  CL0  CL0    CL0  CL2   CL0  CL0  \n",
       "1     CL2    CL0  CL2  CL3    CL0  CL4   CL0  CL0  \n",
       "2     CL0    CL0  CL0  CL0    CL1  CL0   CL0  CL0  \n",
       "3     CL2    CL0  CL0  CL0    CL0  CL2   CL0  CL0  \n",
       "4     CL0    CL1  CL0  CL0    CL2  CL2   CL0  CL0  \n",
       "...   ...    ...  ...  ...    ...  ...   ...  ...  \n",
       "1880  CL0    CL3  CL3  CL0    CL0  CL0   CL0  CL5  \n",
       "1881  CL0    CL3  CL5  CL4    CL4  CL5   CL0  CL0  \n",
       "1882  CL2    CL0  CL2  CL0    CL2  CL6   CL0  CL0  \n",
       "1883  CL0    CL3  CL3  CL0    CL3  CL4   CL0  CL0  \n",
       "1884  CL0    CL3  CL3  CL0    CL3  CL6   CL0  CL2  \n",
       "\n",
       "[1885 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only the drug variable columns\n",
    "df.iloc[:,13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8871fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALC</th>\n",
       "      <th>AMPHET</th>\n",
       "      <th>AMYL</th>\n",
       "      <th>BENZOS</th>\n",
       "      <th>CAFF</th>\n",
       "      <th>CANNABIS</th>\n",
       "      <th>CHOC</th>\n",
       "      <th>COCAINE</th>\n",
       "      <th>CRACK</th>\n",
       "      <th>ECST</th>\n",
       "      <th>HEROIN</th>\n",
       "      <th>KETA</th>\n",
       "      <th>LEGALH</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METH</th>\n",
       "      <th>MUSHRM</th>\n",
       "      <th>NICO</th>\n",
       "      <th>SEMER</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALC AMPHET AMYL BENZOS CAFF CANNABIS CHOC COCAINE CRACK ECST HEROIN KETA  \\\n",
       "0      5      2    0      2    6        0    5       0     0    0      0    0   \n",
       "1      5      2    2      0    6        4    6       3     0    4      0    2   \n",
       "2      6      0    0      0    6        3    4       0     0    0      0    0   \n",
       "3      4      0    0      3    5        2    4       2     0    0      0    2   \n",
       "4      4      1    1      0    6        3    6       0     0    1      0    0   \n",
       "...   ..    ...  ...    ...  ...      ...  ...     ...   ...  ...    ...  ...   \n",
       "1880   5      0    0      0    4        5    4       0     0    0      0    0   \n",
       "1881   5      0    0      0    5        3    4       0     0    2      0    0   \n",
       "1882   4      6    5      5    6        6    6       4     0    4      0    2   \n",
       "1883   5      0    0      0    6        6    5       0     0    3      0    0   \n",
       "1884   4      3    0      3    6        3    6       3     0    3      0    0   \n",
       "\n",
       "     LEGALH LSD METH MUSHRM NICO SEMER VSA  \n",
       "0         0   0    0      0    2     0   0  \n",
       "1         0   2    3      0    4     0   0  \n",
       "2         0   0    0      1    0     0   0  \n",
       "3         0   0    0      0    2     0   0  \n",
       "4         1   0    0      2    2     0   0  \n",
       "...     ...  ..  ...    ...  ...   ...  ..  \n",
       "1880      3   3    0      0    0     0   5  \n",
       "1881      3   5    4      4    5     0   0  \n",
       "1882      0   2    0      2    6     0   0  \n",
       "1883      3   3    0      3    4     0   0  \n",
       "1884      3   3    0      3    6     0   2  \n",
       "\n",
       "[1885 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove 'CL' prefix\n",
    "df.iloc[:,13:] = df.iloc[:,13:].applymap(lambda x: re.sub('CL','',x))\n",
    "df.iloc[:,13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925f9d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1885 entries, 0 to 1884\n",
      "Data columns (total 32 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         1885 non-null   int64  \n",
      " 1   Age        1885 non-null   float64\n",
      " 2   Gender     1885 non-null   float64\n",
      " 3   Education  1885 non-null   float64\n",
      " 4   Country    1885 non-null   float64\n",
      " 5   Ethnicity  1885 non-null   float64\n",
      " 6   NEO_N      1885 non-null   float64\n",
      " 7   NEO_E      1885 non-null   float64\n",
      " 8   NEO_O      1885 non-null   float64\n",
      " 9   NEO_A      1885 non-null   float64\n",
      " 10  NEO_C      1885 non-null   float64\n",
      " 11  IMP        1885 non-null   float64\n",
      " 12  SS         1885 non-null   float64\n",
      " 13  ALC        1885 non-null   int32  \n",
      " 14  AMPHET     1885 non-null   int32  \n",
      " 15  AMYL       1885 non-null   int32  \n",
      " 16  BENZOS     1885 non-null   int32  \n",
      " 17  CAFF       1885 non-null   int32  \n",
      " 18  CANNABIS   1885 non-null   int32  \n",
      " 19  CHOC       1885 non-null   int32  \n",
      " 20  COCAINE    1885 non-null   int32  \n",
      " 21  CRACK      1885 non-null   int32  \n",
      " 22  ECST       1885 non-null   int32  \n",
      " 23  HEROIN     1885 non-null   int32  \n",
      " 24  KETA       1885 non-null   int32  \n",
      " 25  LEGALH     1885 non-null   int32  \n",
      " 26  LSD        1885 non-null   int32  \n",
      " 27  METH       1885 non-null   int32  \n",
      " 28  MUSHRM     1885 non-null   int32  \n",
      " 29  NICO       1885 non-null   int32  \n",
      " 30  SEMER      1885 non-null   int32  \n",
      " 31  VSA        1885 non-null   int32  \n",
      "dtypes: float64(12), int32(19), int64(1)\n",
      "memory usage: 331.5 KB\n"
     ]
    }
   ],
   "source": [
    "#recode as integer field type\n",
    "df.iloc[:,13:] = df.iloc[:,13:].apply(lambda x: x.astype(int))\n",
    "#check for field type of outcomes (should be integers)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290bb20",
   "metadata": {},
   "source": [
    "### Create 3 broader outcome variables (*Stimulants, Depressants and Hallucinogens*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297a7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing function to group drugs to create a new outcome variable\n",
    "def create_drug_test(row):      \n",
    "    return max(row['ALC'],row['AMPHET'],row['AMYL'],\\\n",
    "              row['BENZOS'],row['CANNABIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e213f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALC</th>\n",
       "      <th>AMPHET</th>\n",
       "      <th>AMYL</th>\n",
       "      <th>BENZOS</th>\n",
       "      <th>CAFF</th>\n",
       "      <th>CANNABIS</th>\n",
       "      <th>CHOC</th>\n",
       "      <th>COCAINE</th>\n",
       "      <th>CRACK</th>\n",
       "      <th>ECST</th>\n",
       "      <th>HEROIN</th>\n",
       "      <th>KETA</th>\n",
       "      <th>LEGALH</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METH</th>\n",
       "      <th>MUSHRM</th>\n",
       "      <th>NICO</th>\n",
       "      <th>SEMER</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ALC  AMPHET  AMYL  BENZOS  CAFF  CANNABIS  CHOC  COCAINE  CRACK  ECST  \\\n",
       "0    5       2     0       2     6         0     5        0      0     0   \n",
       "1    5       2     2       0     6         4     6        3      0     4   \n",
       "2    6       0     0       0     6         3     4        0      0     0   \n",
       "\n",
       "   HEROIN  KETA  LEGALH  LSD  METH  MUSHRM  NICO  SEMER  VSA  \n",
       "0       0     0       0    0     0       0     2      0    0  \n",
       "1       0     2       0    2     3       0     4      0    0  \n",
       "2       0     0       0    0     0       1     0      0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    6\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test on first three throws - before and after\n",
    "display(df.iloc[:3,13:])\n",
    "\n",
    "#selection from row\n",
    "display(df.iloc[:3,13:].apply(lambda x: create_drug_test(x), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e7eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to group drugs to create a new stimulants outcome variable\n",
    "def create_stimulants(row):      \n",
    "    return max(row['AMPHET'],row['NICO'],row['COCAINE'],\\\n",
    "              row['CRACK'],row['CAFF'],row['CHOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea18d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to group drugs to create a new depressants outcome variable\n",
    "def create_depressants(row):      \n",
    "    return max(row['ALC'],row['AMYL'],row['BENZOS'],row['VSA'],row['HEROIN'],\\\n",
    "              row['METH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f793f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to group drugs to create a new hallucinogens outcome variable\n",
    "def create_hallucinogens(row):      \n",
    "    return max(row['CANNABIS'],row['ECST'],row['KETA'],row['LSD'],\\\n",
    "               row['MUSHRM'],row['LEGALH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d08ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stimulants\"] = df.iloc[:,13:].apply(lambda x: create_stimulants(x).astype(int), axis=1)\n",
    "df[\"depressants\"] = df.iloc[:,13:].apply(lambda x: create_depressants(x).astype(int), axis=1)\n",
    "df[\"hallucinogens\"] = df.iloc[:,13:].apply(lambda x: create_hallucinogens(x).astype(int), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef395be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>NEO_N</th>\n",
       "      <th>NEO_E</th>\n",
       "      <th>NEO_O</th>\n",
       "      <th>NEO_A</th>\n",
       "      <th>...</th>\n",
       "      <th>LEGALH</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METH</th>\n",
       "      <th>MUSHRM</th>\n",
       "      <th>NICO</th>\n",
       "      <th>SEMER</th>\n",
       "      <th>VSA</th>\n",
       "      <th>stimulants</th>\n",
       "      <th>depressants</th>\n",
       "      <th>hallucinogens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      Age   Gender  Education  Country  Ethnicity    NEO_N    NEO_E  \\\n",
       "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
       "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "        NEO_O    NEO_A  ...  LEGALH  LSD  METH  MUSHRM  NICO  SEMER  VSA  \\\n",
       "0    -0.58331 -0.91699  ...       0    0     0       0     2      0    0   \n",
       "1     1.43533  0.76096  ...       0    2     3       0     4      0    0   \n",
       "2    -0.84732 -1.62090  ...       0    0     0       1     0      0    0   \n",
       "3    -0.01928  0.59042  ...       0    0     0       0     2      0    0   \n",
       "4    -0.45174 -0.30172  ...       1    0     0       2     2      0    0   \n",
       "...       ...      ...  ...     ...  ...   ...     ...   ...    ...  ...   \n",
       "1880  1.88511  0.76096  ...       3    3     0       0     0      0    5   \n",
       "1881  0.58331  0.76096  ...       3    5     4       4     5      0    0   \n",
       "1882 -1.27553 -1.77200  ...       0    2     0       2     6      0    0   \n",
       "1883  0.29338 -1.62090  ...       3    3     0       3     4      0    0   \n",
       "1884  1.65653  1.11406  ...       3    3     0       3     6      0    2   \n",
       "\n",
       "      stimulants  depressants  hallucinogens  \n",
       "0              6            5              0  \n",
       "1              6            5              4  \n",
       "2              6            6              3  \n",
       "3              5            4              2  \n",
       "4              6            4              3  \n",
       "...          ...          ...            ...  \n",
       "1880           4            5              5  \n",
       "1881           5            5              5  \n",
       "1882           6            5              6  \n",
       "1883           6            5              6  \n",
       "1884           6            4              3  \n",
       "\n",
       "[1885 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bcdc40",
   "metadata": {},
   "source": [
    "### Recode from 6 levels to 3 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30004f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define recoding function\n",
    "def recode(val):\n",
    "    if val >= 4:\n",
    "        return 3\n",
    "    if (val >=2) & (val< 4):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a955f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply recoding\n",
    "df[['stim_final','dep_final','hallu_final']] = df[['stimulants','depressants','hallucinogens']].applymap(lambda x: recode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a855a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>NEO_N</th>\n",
       "      <th>NEO_E</th>\n",
       "      <th>NEO_O</th>\n",
       "      <th>NEO_A</th>\n",
       "      <th>...</th>\n",
       "      <th>MUSHRM</th>\n",
       "      <th>NICO</th>\n",
       "      <th>SEMER</th>\n",
       "      <th>VSA</th>\n",
       "      <th>stimulants</th>\n",
       "      <th>depressants</th>\n",
       "      <th>hallucinogens</th>\n",
       "      <th>stim_final</th>\n",
       "      <th>dep_final</th>\n",
       "      <th>hallu_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      Age   Gender  Education  Country  Ethnicity    NEO_N    NEO_E  \\\n",
       "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
       "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "        NEO_O    NEO_A  ...  MUSHRM  NICO  SEMER  VSA  stimulants  \\\n",
       "0    -0.58331 -0.91699  ...       0     2      0    0           6   \n",
       "1     1.43533  0.76096  ...       0     4      0    0           6   \n",
       "2    -0.84732 -1.62090  ...       1     0      0    0           6   \n",
       "3    -0.01928  0.59042  ...       0     2      0    0           5   \n",
       "4    -0.45174 -0.30172  ...       2     2      0    0           6   \n",
       "...       ...      ...  ...     ...   ...    ...  ...         ...   \n",
       "1880  1.88511  0.76096  ...       0     0      0    5           4   \n",
       "1881  0.58331  0.76096  ...       4     5      0    0           5   \n",
       "1882 -1.27553 -1.77200  ...       2     6      0    0           6   \n",
       "1883  0.29338 -1.62090  ...       3     4      0    0           6   \n",
       "1884  1.65653  1.11406  ...       3     6      0    2           6   \n",
       "\n",
       "      depressants  hallucinogens  stim_final  dep_final  hallu_final  \n",
       "0               5              0           3          3            0  \n",
       "1               5              4           3          3            3  \n",
       "2               6              3           3          3            2  \n",
       "3               4              2           3          3            2  \n",
       "4               4              3           3          3            2  \n",
       "...           ...            ...         ...        ...          ...  \n",
       "1880            5              5           3          3            3  \n",
       "1881            5              5           3          3            3  \n",
       "1882            5              6           3          3            3  \n",
       "1883            5              6           3          3            3  \n",
       "1884            4              3           3          3            2  \n",
       "\n",
       "[1885 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5be8533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stim_final</th>\n",
       "      <th>dep_final</th>\n",
       "      <th>hallu_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>215</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1873</td>\n",
       "      <td>1628</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stim_final  dep_final  hallu_final\n",
       "0           4         42          584\n",
       "2           8        215          418\n",
       "3        1873       1628          883"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at value counts to ensure only 3 possible classes for each drug outcome\n",
    "df[['stim_final','dep_final','hallu_final']].apply(df.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f52c087",
   "metadata": {},
   "source": [
    "# Initial Models\n",
    "\n",
    "In the following section, initial models are calibrated for the _**stimulants outcome variable**_. The models calibrated are:\n",
    "\n",
    "- Support Vector Machines\n",
    "- Multinomial Logit Regression (Softmax Regression)\n",
    "- K-Nearest Neighbours classifier\n",
    "- Decision Trees\n",
    "- Random Forests/Gradient Boosted Trees\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- Neural Network\n",
    "\n",
    "The model hyperparameters are default values for the time being and class have not yet been balanced. Another set of models will be run with balanced classes (SMOTE will be applied).\n",
    "\n",
    "Model accuracy scores are also quickly calculated for the test set (test/train split: 30/70)\n",
    "\n",
    "The section below provides a description of the methods used before going into the actual model calibration, fitting and scoring.\n",
    "\n",
    "\n",
    "**Support Vector Machine**\n",
    "\n",
    "Support Vector Machines are a supervised learning method that can be used for both classification and regression (Shmilovici, 2009). Knowing the labels for the data, the algorithm tries to find an optimal decision boundary known as a hyperplane in n-dimensional space (n is the number input features used) that can correctly classify the data points to the output labels given. The hyperplane that is selected is the one that separates the positive and negative classes by greatest margin, to allow for greater generalization. The hyperplane is usually a linear equation as the boundary is a straight line. SVMs however can be adapted to multiclass problems and non-linear hyperplanes (Burkov, 2019).\n",
    "\n",
    "**Logistic Regression and Multinomial Logits**\n",
    "\n",
    "Logistic Regression is a classification model which models the probabilities for binary outcomes (two outcomes) (Burkov, 2019). In logistic regression, a linear combination of inputs is squeezed by the standard logistic function or sigmoid function into a codomain of 0 and 1, resulting in an output of log odds. Negative values of the log odds can map to “0” and positive ones can map to “1”.\n",
    "\n",
    "We can also map back the probabilities by the following equation (Kleinbaum, Dietz, Gail, Klein, & Klein, 2002):\n",
    "\n",
    "〖p (x;b,w)=log〗⁡〖(p(x))/(1-p(x))〗  =  e^(β0+x·β )/(1+ e^(β0+x·β)  )  +  =  1/(1 + e^(-(β0+x·β)) )  \n",
    "\n",
    "A threshold probability is set (i.e., .5), and whenever p > .5 it will result in the positive (“1”). Multinomial Logistic Regression extends this model to produce probabilities for multiple classes (more than 2).\n",
    "\n",
    "**k-Nearest Neighbors Classifier**\n",
    "\n",
    "The k-Nearest Neighbors algorithm is a non-parametric supervised learning algorithm that can be used to classify or perform regression. When the algorithm sees a new sample x that does not have a label, it finds k training examples that are closest to x according to distances between n input features. Distance metrics include Manhattan distance or cosine similarity are calculated for all input features between x and data points in the training set. The k data points that have the smallest distance are deemed the closest to the x sample, and the majority label among the k data points is given to x (Burkov, 2019).\n",
    "\n",
    "**Decision Tree/Random Forest/Gradient Boosting Tree**\n",
    "\n",
    "A decision tree is a non-parametric model that builds an acyclic graph (Burkov, 2019). The algorithm chooses a rule to split the data on (branching from nodes). When a value is above a threshold it follows one side of the branch otherwise it goes to the other one. When no more splits can be made, a leaf node is reached, and a decision is reached about which class to assign the data point. To determine whether a split is good, Entropy is calculated where high levels of entropy mean all values of a variable are probable and low entropy is where only one value is possible. A random forest extends this concept by generating multiple trees, where it randomly selects a new subset of features at each split. The outputs are combined at the end (i.e., through majority vote) to get a final classification. In doing so, this avoids correlated trees which would decrease the accuracy of prediction and reduces the variance of the final model to minimize the chance of overfitting. Another extension of the decision tree is the Gradient Boosting Tree, where multiple trees are built, but this time, each tree depends on the last tree, as the residuals for the last tree are calculated and are added back in as new labels. This modified training set is then used to produce the next tree which will have even smaller errors (i.e., smaller residuals) (Burkov, 2019).\n",
    "\n",
    "**Neural Networks**\n",
    "\n",
    "A neural network consists of a series of nested functions called layers (Burkov, 2019). The first layer is the input layer which holds an activation function (i.e., a logistic regression function) chosen by the analyst and can have multiple units. The last layer is the output layer and has one unit to combine all inputs from the second last layer into one output value. To get from the inputs (x) to the first layer, different weights are applied to each input before they are fed into all the units in the first layer. If the activation function is activated the output value is passed to the next set of units in the next layer. This continues until the output layer which produces a final regression value or class prediction. The neural network then assesses the output with the expected output and then uses that information in a process called back propagation to adjust the weights before each layer to produce a better final overall prediction.\n",
    "\n",
    "\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0fa669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "754ba21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset independent variables\n",
    "x_vars = df.iloc[:,:13]\n",
    "\n",
    "#subset outcome variables\n",
    "out = df[['stim_final','dep_final','hallu_final']]\n",
    "\n",
    "\n",
    "#creat test train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_vars,out, test_size=.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d1857",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888e950e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#instantiate SVM object\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "#fit\n",
    "SVC = lin_clf.fit(X_train,y_train[\"stim_final\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0daa4752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28779840848806365"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score on test data set\n",
    "lin_clf.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d370d6",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9221a16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#instantiate logistic regression\n",
    "mnlogit = LogisticRegression(multi_class ='multinomial',fit_intercept = True , solver ='lbfgs').fit(X_train \n",
    "                                                                                                    , y_train[\"stim_final\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ba569a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938107869142352"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score for training set\n",
    "mnlogit.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d30d5d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993368700265252"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score for test set\n",
    "mnlogit.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c099b",
   "metadata": {},
   "source": [
    "## k-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dad0a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate k-nnclassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#fit to data\n",
    "neigh.fit(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed12d5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993368700265252"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score\n",
    "neigh.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4090fb",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5851f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate DT\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#fit to data\n",
    "clf.fit(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88d6d357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827586206896551"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score\n",
    "clf.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec52fc9",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb1c21be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate GradientBoostingRegressor\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "#fit to data\n",
    "reg.fit(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41757e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974688091030849"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score - training set\n",
    "reg.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "726a9c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.0525862987180155"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score -test set\n",
    "reg.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27ab90",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36506cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate LDA\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "#fit to data\n",
    "LDA.fit(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83e50be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920424403183024"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score - training set\n",
    "LDA.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa34dd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907161803713528"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score -test set\n",
    "LDA.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a1c9c2",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "368f8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate and fit NN\n",
    "NN = MLPClassifier(random_state=1, max_iter=300).fit(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a817a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938107869142352"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score - train set\n",
    "NN.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5515ece0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993368700265252"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score -test set\n",
    "NN.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb68c91",
   "metadata": {},
   "source": [
    "# Rebalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dacfee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04243fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate SMOTE() object\n",
    "over = SMOTE(k_neighbors=2,random_state=42)\n",
    "#over = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "406e068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversample on only the training data set\n",
    "X_sampled,y_sampled = over.fit_resample(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "975e3db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1124\n",
       "2    1124\n",
       "3    1124\n",
       "Name: stim_final, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that sampled y values only have the three expected classes\n",
    "y_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc086709",
   "metadata": {},
   "source": [
    "## Rebalanced - Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33bef5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#instantiate SVM object\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "#fit to data\n",
    "SVC = lin_clf.fit(X_sampled,y_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e41cbe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-adccc9f5401f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#accuracy score on test data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mSVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stim_final\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#accuracy score on test data set - incorrect way due to how probabilities are stored\n",
    "SVC.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c57e3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4ab18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve probabilities using decision_function\n",
    "y_prob = lin_clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "818484c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57081771, -1.0369794 ,  1.70708487],\n",
       "       [-1.42211159, -0.97718883,  2.41747362],\n",
       "       [-0.61152739, -1.39752618,  2.85829361],\n",
       "       ...,\n",
       "       [-0.7132772 , -0.87108006,  1.86228046],\n",
       "       [ 0.49812871, -1.19690226,  4.05743252],\n",
       "       [ 0.28663167,  0.50902497,  1.74612586]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show y probabilities\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ab6a87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4986648865153538"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #calculate final roc_auc_score\n",
    "roc_auc_score(y_test[\"stim_final\"],lin_clf.predict(X_test), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cae91",
   "metadata": {},
   "source": [
    "## Rebalanced - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "321ff66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate logistic regression\n",
    "mnlogit = LogisticRegression(multi_class ='multinomial',fit_intercept = True , C =0.001,\n",
    "                             max_iter=10000 ).fit(X_sampled,y_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21aae726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5888594164456233"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score for training set\n",
    "mnlogit.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7239750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6021220159151194"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score on test data set\n",
    "mnlogit.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fafc05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05295425, 0.6860109 , 0.26103485],\n",
       "       [0.03307232, 0.65860127, 0.30832641],\n",
       "       [0.05434412, 0.35640378, 0.5892521 ],\n",
       "       ...,\n",
       "       [0.0651547 , 0.73431628, 0.20052902],\n",
       "       [0.21888602, 0.11546577, 0.66564821],\n",
       "       [0.09948794, 0.7003346 , 0.20017747]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get probabilities for each class for each individual\n",
    "mnlogit.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3396517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    749\n",
       "2      5\n",
       "Name: stim_final, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check value counts\n",
    "y_test[\"stim_final\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f43da370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5013351134846462"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get roc_auc_score   \n",
    "roc_auc_score(y_test[\"stim_final\"],mnlogit.predict(X_test), multi_class='ovo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae38b7f",
   "metadata": {},
   "source": [
    "## Rebalanced  - K-nn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37148498",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    #instantiate k-NN\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    \n",
    "    #fit\n",
    "    knn.fit(X_sampled,y_sampled)\n",
    "    \n",
    "    #create prediction array\n",
    "    pred_i = knn.predict(X_test)\n",
    "    \n",
    "    #calculate error_rate between predicted vs actual\n",
    "    error_rate.append(np.mean(pred_i != y_test[\"stim_final\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a397175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot error rate by K value to determine best k\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    " markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64019eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate k-nnclassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "#fit\n",
    "neigh.fit(X_sampled,y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84fe79bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.253315649867374"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score\n",
    "neigh.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30dccd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.256475300400534"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve final auc score \n",
    "roc_auc_score(y_test[\"stim_final\"],neigh.predict(X_test), multi_class='ovo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f700fe",
   "metadata": {},
   "source": [
    "## Rebalanced - Decision Tree\n",
    "\n",
    "### Using pruning to prevent over fitting - Determining the correct ccp_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d6e193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use cost_complexity_pruning_path() to determine alphas to test\n",
    "path = clf.cost_complexity_pruning_path(X_sampled,y_sampled)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c578d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 1 with ccp_alpha: 0.20578540678660684\n"
     ]
    }
   ],
   "source": [
    "#store DT objects instantiated with different alphas and fitted on smote balanced data\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_sampled,y_sampled)\n",
    "    clfs.append(clf)\n",
    "print(\n",
    "    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "        clfs[-1].tree_.node_count, ccp_alphas[-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb3f8388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot all but last model/alha\n",
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "#plot of nodes vs alpha and depth vs alpha\n",
    "\n",
    "#array of node counts\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "\n",
    "#array of depths\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26d3a764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the accuracy of test and train datasets vs alpha\n",
    "train_scores = [clf.score(X_train,y_train[\"stim_final\"]) for clf in clfs]\n",
    "test_scores = [clf.score(X_test,y_test[\"stim_final\"]) for clf in clfs]\n",
    "\n",
    "#plot results\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f28ce",
   "metadata": {},
   "source": [
    "### Fit Using the alpha determined above (0.05) - most stable accuracy across increasing alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c1e7d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.05, random_state=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate DT\n",
    "clf = DecisionTreeClassifier(random_state=0, ccp_alpha=0.05)\n",
    "\n",
    "#fit model\n",
    "clf.fit(X_sampled,y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3ca1929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7493368700265252"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score\n",
    "clf.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc465bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48624833110814425"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get auc score\n",
    "roc_auc_score(y_test[\"stim_final\"],clf.predict(X_test), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548373f",
   "metadata": {},
   "source": [
    "## Rebalanced - Boosted Tree\n",
    "\n",
    "### Fit Using the alpha determined above (0.05) - most stable accuracy across increasing alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67892cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.05, random_state=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate GradientBoostingClassifier\n",
    "reg = GradientBoostingClassifier(random_state=0, ccp_alpha=0.05)\n",
    "\n",
    "#fit model\n",
    "reg.fit(X_sampled,y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b59891ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8682581786030061"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score - training set\n",
    "reg.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bead5227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713527851458885"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score -test set\n",
    "reg.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590ebd2",
   "metadata": {},
   "source": [
    "## Rebalanced - Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8b6b2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate LDA\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "#fit to the data\n",
    "LDA.fit(X_sampled,y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7105fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.649867374005305"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score - training set\n",
    "LDA.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14a08c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6830238726790451"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score -test set\n",
    "LDA.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acaa132",
   "metadata": {},
   "source": [
    "## Rebalanced - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fdc73db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate\n",
    "NN = MLPClassifier(random_state=1, max_iter=300).fit(X_sampled,y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bd23582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283819628647215"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score - train set\n",
    "NN.score(X_train,y_train[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c57317e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124668435013262"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score -test set\n",
    "NN.score(X_test,y_test[\"stim_final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef88286",
   "metadata": {},
   "source": [
    "# Evaluation Metrics - AUC calculations and plots\n",
    "\n",
    "The ROC curve is an evaluation metric to evaluate the output of a classifier. True positive rate is plotted on the y-axis and false positive rate is plotted on the x-axis. Goes from 0 to 1 from both axes.\n",
    "\n",
    "\"Steepness\" is important to maximize the TPR while minimizing the FPR - the ideal is 1 TPR and 0 FPR. \n",
    "\n",
    "Typically are used in binary classification evaluation, however, since we have a multi-class problem (three classes), we need to binarize the output.\n",
    "\n",
    "In implementing this approach, an ROC curve can be drawn per label. An overall ROC curve can also be created by considering each element of the label indicator matrix as a binary prediction (micro-averaging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca3e39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries to create AUC with OvR appraoch\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a1af7",
   "metadata": {},
   "source": [
    "## Linear Classifier - AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0f6febdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time in seconds: 0.8043670654296875\n"
     ]
    }
   ],
   "source": [
    "#store start time\n",
    "start = time.time()\n",
    "# Binarize the output\n",
    "y = label_binarize(y_sampled, classes=[0, 2, 3])\n",
    "#retrieve number of class\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "#set random state to make repeatable\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sampled, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(\n",
    "    #LinearDiscriminantAnalysis()\n",
    "    GradientBoostingClassifier(random_state=0, ccp_alpha=0.05)\n",
    "    #MLPClassifier(random_state=1, max_iter=300)\n",
    "    #DecisionTreeClassifier(random_state=0, ccp_alpha=0.05)\n",
    "    #KNeighborsClassifier(n_neighbors=20)\n",
    "    #LogisticRegression(random_state=42)\n",
    "    #svm.SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    ")\n",
    "\n",
    "#model and get probability\n",
    "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "print(f\"Total Time in seconds: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "022604f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "#loop through each class\n",
    "for i in range(n_classes):\n",
    "    #get fpr and tpr for each class from roc_curve\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    #get the area under the curve\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "afc6563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.858706883707965,\n",
       " 1: 0.9420883940620783,\n",
       " 2: 0.9237041157700361,\n",
       " 'micro': 0.8973781360418434}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view auc\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "eb640076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34341637010676157"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare with accuracy in model method\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "84b78acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time in seconds: 0.11797881126403809\n"
     ]
    }
   ],
   "source": [
    "#create start time\n",
    "start = time.time()\n",
    "# Binarize the output\n",
    "y = label_binarize(y_sampled, classes=[0, 2, 3])\n",
    "n_classes = y.shape[1]\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sampled, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "#fit and get probability\n",
    "y_score = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#print score\n",
    "print(f\"Total Time in seconds: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6dd8d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "#loop through every class\n",
    "for i in range(n_classes):\n",
    "    \n",
    "    #get fpr and tpr for each class from roc_curve\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:,i])\n",
    "    \n",
    "    #get the area under the curve\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ed75a395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6806498743217458,\n",
       " 1: 0.7350684403315983,\n",
       " 2: 0.6225111837378022,\n",
       " 'micro': 0.6760083036773428}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view auc\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "18f434ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48279952550415184"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get accuracy score from model method\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate decision tree\n",
    "DecisionTreeClassifier(random_state=0, ccp_alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6f89cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time in seconds: 0.5354225635528564\n"
     ]
    }
   ],
   "source": [
    "#get start time\n",
    "start = time.time()\n",
    "# Binarize the output\n",
    "#y = y_sampled\n",
    "y = label_binarize(y_sampled, classes=[0, 2, 3])\n",
    "#get number of classes for y variable\n",
    "n_classes = y.shape[1]\n",
    "#choose randome state for repeatability\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sampled, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "#classifier = DecisionTreeClassifier(random_state=0, ccp_alpha=0.05)\n",
    "#classifier = GradientBoostingClassifier(random_state=0, ccp_alpha=0.05)\n",
    "\n",
    "#instantiate Neural Network classifier\n",
    "classifier = MLPClassifier(random_state=1, max_iter=300)\n",
    "\n",
    "#fit and get probabilities\n",
    "y_score = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#print total time\n",
    "print(f\"Total Time in seconds: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f040fdda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0be34dc5a416>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#loop through classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#get fpr and tpr for each class with roc_curve()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "#loop through classes\n",
    "for i in range(n_classes):\n",
    "    \n",
    "    #get fpr and tpr for each class with roc_curve()\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:,i])\n",
    "    \n",
    "    #get auc for class\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "616bb5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9819700967458224,\n",
       " 1: 0.9802631578947368,\n",
       " 2: 0.9060913705583756,\n",
       " 'micro': 0.9543297746144722}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show auc\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ecc849ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9175563463819691"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get accuracy score from classifier\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "da22eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classification report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "de22c512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.967324</td>\n",
       "      <td>0.974496</td>\n",
       "      <td>0.970897</td>\n",
       "      <td>3372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.948224</td>\n",
       "      <td>0.934164</td>\n",
       "      <td>0.941141</td>\n",
       "      <td>1686.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.961052</td>\n",
       "      <td>0.961052</td>\n",
       "      <td>0.961052</td>\n",
       "      <td>0.961052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.957774</td>\n",
       "      <td>0.954330</td>\n",
       "      <td>0.956019</td>\n",
       "      <td>5058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.960957</td>\n",
       "      <td>0.961052</td>\n",
       "      <td>0.960978</td>\n",
       "      <td>5058.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.967324  0.974496  0.970897  3372.000000\n",
       "1              0.948224  0.934164  0.941141  1686.000000\n",
       "accuracy       0.961052  0.961052  0.961052     0.961052\n",
       "macro avg      0.957774  0.954330  0.956019  5058.000000\n",
       "weighted avg   0.960957  0.961052  0.960978  5058.000000"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine report table\n",
    "pd.DataFrame(classification_report(y_test.ravel(), y_score.ravel(), output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a2575207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1686"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da8bd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc21faee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at parameters for classifier (RandomForestClassifier as the example)\n",
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ad3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the parameter grid for GridSearchCV - parameters to try to optimize\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()], #Parameters for LogisticRegression\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear','newton-cg', 'lbfgs','saga']},\n",
    "    \n",
    "    {'classifier' : [RandomForestClassifier()], #Parameters for RandomForestClassifier\n",
    "    'classifier__n_estimators' : [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'classifier__max_features' : ['auto', 'sqrt','log2'],\n",
    "    'classifier__bootstrap' : [True, False],\n",
    "    'classifier__max_depth': [5,10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "     'classifier__min_samples_leaf': [1, 2, 4],\n",
    "     'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__criterion': ['gini','entropy','log_loss']},\n",
    "    \n",
    "    \n",
    "    {'classifier' : [MLPClassifier()], #Parameters for Neural Network\n",
    "    'classifier__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'classifier__activation': ['tanh', 'relu'],\n",
    "    'classifier__solver': ['sgd', 'adam'],\n",
    "    'classifier__alpha': [0.0001, 0.05, 0.1],\n",
    "    'classifier__learning_rate': ['constant','adaptive', 'invscaling'],\n",
    "    'classifier__max_iter' :[200,300,400]}\n",
    "    \n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a668b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
